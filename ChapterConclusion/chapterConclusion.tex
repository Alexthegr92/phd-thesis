\chapter{Conclusions and Future Work}
\section{Conclusions}
An approach to networked real-time physics simulations that is scalable and alleviates the processing limitation of a single server has been presented. Only open-source software has been used in our approach and our algorithm has been developed in a way that is agnostic to any specific application technology.

In Chapter \ref{ProbDef} the challenges facing distributed real-time physics were defined, possible solutions were addressed and our chosen solution, AP, was presented and justified. The origination of the aura calculation used for the auras in AP was also presented. The implementation of AP was discussed in Chapter \ref{Implementation}, including potential topologies that could be used by a system using AP and the breakdown of the components of each server. Chapter \ref{Implementation} also gave an overview of the visualiser used by the system, which is responsible for rendering the state of the simulation through the use of replicas. Its features and their implementation details were discussed.

In Chapter \ref{Results}, the design and results of the experiments were presented for addressing the questions set out by this study: "Can scalable real-time physics simulations be achieved?" and "Can real-time physics simulations remain correct when scaled?".

The experiments carried out in this study establish that the approach is scalable, as demonstrated by the addition of servers improving the performance of the system when simulating an increasingly large number of objects. This study has demonstrated that a standard real-time physics engine (in this case, PhysX) may be incorporated into our scalable real-time physics system and achieve performance that is acceptable for real-time distributed simulations such as networked games.

The correctness of collisions in AP have been measured and evaluated. The experiments conducted in this study establish that collisions remain correct in AP, even when objects interact while intersecting the boundary. This has been shown to be true while increasing each of the following factors: speed; latency and frame-time. Collisions remain correct up to the tolerance values for each factor and begin to show errors as soon as the tolerance is exceeded, demonstrating the correctness of the aura calculation used in AP. The holds true if thrashing collisions are excluded from the results. The number of thrashing collisions and amount of times thrashed were both measured, potential solutions to the thrashing problem were proposed in \ref{Thrashing} and we assume that these errors will be fixed in future work.

In addition to the aura factors being tested, the effects of packet loss on the system have also been explored and the limits of AP with increasing packet loss have been shown. This research demonstrates that collisions of rigid-bodies can be handled correctly in a scalable, distributed real-time physics system, even when those collisions take place on or near a server-region boundary.

\section{Future Work}
Work will continue to carry out experiments to determine the effects that changing each of the aura tolerances has on the performance and scalability of AP. Future work will enable each tolerance value to be dynamic and the aura size could adapt with the changing conditions of the system. This would improve performance when factors are low and maintain correctness when factors are high.

Acceleration could also be factored into the aura calculation. The velocity between time steps is often limited and using an acceleration tolerance would allow for smaller auras for slow moving objects. Smaller auras lead to better performance as it leads to fewer aura broadcasts and object migrations. Note that the acceleration tolerance could only apply to the displacement calculation of the local object, as the velocity of a potential remote object is unknown.
%Reference where smaller auras improving performance are explained

An alternative to just aura position and radius being sent over the network would be to send more details of the object projecting the aura. This could include bounding sphere and velocity and would allow the receiving server to determine the size of the aura. Under changing conditions, such as changes in latency the receiving server could dynamically change the size of the auras without the need for the sending server to send the new sizes of the auras.

The implementation of AP could be improved through the separation of the main server update rate and the network tick rate (network update frequency) as discussed in \ref{update-rate-test-values}. These two update rates are often decoupled in video games, as it enables the server to maintain an accurate simulation while allowing for a lower tick rate to reduce the network requirements i.e. bandwidth. A lower frequency tick rate would mean a larger aura is required as there would be a longer delay between aura creation/update/collisions events and messages being sent and a longer delay between a message being received and processed. Larger auras would likely lead to a drop in performance. However, a lower frequency tick rate would mean lower processing overhead for sending, receiving and processing network messages. This trade-off could be investigated to determine how it affects performance of the overall system.

%Future experiments may also involve the decoupling of ``update rate'' from ``tick rate'' as described in Section \ref{update-rate-test-values}. As some video games opt to maintain a high internal tick rate to improve simulation accuracy but use a lower or variable update rate to save bandwidth when communicating with networked peers, it would be of interest to examine how doing so would affect the correctness of aura projection in these configurations.


Scalability could be improved through the use of load-balancing and run-time elastic resources. Server regions could use dynamic boundaries to balance the workload of the simulation between servers. This could make use of existing research into graph-partitioning, where objects are treated as edges and overlapping auras are undirected edges. Boundaries could be moved to reduce the number of boundary-edge intersections. In addition, statistical modelling and analysis could be employed to predict future states of the simulation in order to reduce boundary-edge intersections that will occur. Through the use of elastic resources, it would also be possible to `spin-up' and `wind-down' nodes as required by the simulation. Combined with dynamic boundaries between servers, the simulation workload could be moved to newly created servers, by dividing existing server regions when computational requirements are high. When they are low, the regions from multiple servers could be consolidated into a single server, reducing the number of servers required, resulting in lower financial cost.

%, new regions will need to be created during run-time (either dividing existing regions or expanding the simulation area). New nodes will need to be launched during run-time, using  and a method for re-dividing up the workload between the new and existing nodes will be required. This would require on dem

%Additionally, on-demand dynamic load balancing will be explored to enable improvements in scalability. This will leverage run-time resource (re)allocation in order to maintain efficient distribution of cloud-based processing facilities in response to changes in the simulated environment. Simulations of objects that can freely interact with one another with a high degree of fidelity are never uniform, and therefore on-line statistical modelling and analysis will be fundamental to predicting where additional computational units are required. This will necessitate a transition from fixed world region boundaries to dynamic re-partitioning, which we expect will improve performance by reducing the number of auras being projected and the number of objects being migrated, leading to an overall reduction in bandwidth usage.

The use of containers, such as Docker, for the deployment of AP could also be investigated and compared with the current implementation that uses virtual machine cloud instances. Containers would allow for efficient provisioning and management of compute resources within the system as they enable more precise control over resources allocated. In addition, containers provide faster on-demanding provisioning of resources. Using containers instead of cloud instances may require additional overhead in terms of performance, which could be investigated and the trade-off between cloud instances and the benefits of containers explored.
%The use of modern cloud technologies will also be researched, such as containers and container orchestration in order to facilitate efficient provisioning and management of additional compute resources within a distributed physics simulation. The use of lightweight containers versus virtual machine instances may allow for more precise control of compute resource allocation and faster on-demand provisioning, which would lend itself well to streamed gaming applications.

Future cloud deployment architectures could also be investigated. The use of `overseer' nodes to enable scalability in terms of clients connected could be developed and measured, and their ability to provide a level of fault-tolerance in the event of node failure could be tested. Overseer nodes could also be located at the edge, providing lower latencies for connecting clients, but at the cost of a higher latency between overseer nodes and the cloud-based simulation servers and the other overseer nodes.

%Render nodes
%Edge computing

AP works on the principle that any two bodies that may be interacting are always being simulated on the same server. An alternative technique to this would be Cross-Boundary Interaction, as discussed in \ref{ConsideredSolutions}, allowing for bodies to interact across region boundaries i.e. objects that are being simulated on two different servers interacting over the network. There are likely various advantages and disadvantages of Cross-Boundary Interaction compared to Aura Projection, which could be explored and evaluated. The two solutions may have better performance in different situations (such as a large cluster on either side of a boundary) and a solutions which uses both techniques in different circumstances could be developed.

An important feature of a physics engine is the ability to query the state of the simulation. A typical example of this would be a ray-cast, in which a ray is cast between two points in the simulation space to find intersecting bodies. %Ray-casts are commonly used in first-person shooting games, i.e. a ray is cast from the player's weapon to a given distance, and objects that intersect the ray are returned from the query.
Distributed physics adds an extra level of complexity to this as the query may concern spaces and/or objects being simulated on different servers. In the case of spatially-partitioned solutions, the query could overlap the region boundary and in order for the query to be completed, a round-trip of messages between the two servers would be required. If the query is blocking/synchronous (execution cannot continue until the query is complete), this would introduce a large amount of wait time (at least double the network latency). Another option would be to use asynchronous queries, the results of which get returned using a function callback as soon as the results have been received. However this is more complex than a query on a centralised simulation which can return the results synchronously without any network delay.

%Constraints
AP is currently limited to the migration of single rigid-bodies between servers. Support for other physical entities such as groups of attached rigid-bodies, soft-bodies and constraints within AP could be added and investigated.