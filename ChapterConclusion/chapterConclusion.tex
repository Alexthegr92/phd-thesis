\chapter{Conclusions and Future Work}
An approach to networked real-time physics simulations that is scalable and alleviates the processing limitation of a single server has been presented. Only open-source software has been used in our approach and our algorithm has been developed in a way that is agnostic to any specific application technology.

Our experiments establish that the approach is scalable, as demonstrated by the addition of servers improving the performance of the system when simulating an increasingly large number of objects. This study has demonstrated that a standard real-time physics engine (in this case, PhysX) may be incorporated into our scalable real-time physics system and achieve performance that is acceptable for real-time distributed simulations such as networked games.

We have measured and evaluated the correctness of collisions in AP. Our experiments establish that collisions remain correct in AP, even when objects interact while intersecting the boundary. This has been shown to be true while increasing each of the following factors: speed; latency and frame-time. Collisions remain correct up to the tolerance values for each factor and begin to show errors as soon as the tolerance is exceeded, demonstrating the correctness of the aura calculation used in AP. In addition the effects of packet loss on the system have also been explored and the limits of AP with increasing packet loss have been shown. This paper demonstrates that collisions of rigid-bodies can be handled correctly in a scalable, distributed real-time physics system, even when those collisions take place on or near a server-region boundary.

%Thrashing, if we do it?

Our continuing work will be to carry out experiments to determine the effects that changing each of the aura tolerances has on the performance and scalability of AP. Future work will enable each tolerance value to be dynamic and the aura size could adapt with the changing conditions of the system. This would improve performance when factors are low and maintain correctness when factors are high.
%Future experiments may also involve the decoupling of ``update rate'' from ``tick rate'' as described in Section \ref{update-rate-test-values}. As some video games opt to maintain a high internal tick rate to improve simulation accuracy but use a lower or variable update rate to save bandwidth when communicating with networked peers, it would be of interest to examine how doing so would affect the correctness of aura projection in these configurations.
Additionally, on-demand dynamic load balancing will be explored to enable improvements in scalability. This will leverage run-time resource (re)allocation in order to maintain efficient distribution of cloud-based processing facilities in response to changes in the simulated environment. Simulations of objects that can freely interact with one another with a high degree of fidelity are never uniform, and therefore on-line statistical modelling and analysis will be fundamental to predicting where additional computational units are required. 

%This will necessitate a transition from fixed world region boundaries to dynamic re-partitioning, which we expect will improve performance by reducing the number of auras being projected and the number of objects being migrated, leading to an overall reduction in bandwidth usage.

%We will also be researching the use of modern cloud technologies such as containers and container orchestration in order to facilitate efficient provisioning and management of additional compute resources within a distributed physics simulation. The use of lightweight containers versus virtual machine instances may allow for more precise control of compute resource allocation and faster on-demand provisioning, which would lend itself well to streamed gaming applications.